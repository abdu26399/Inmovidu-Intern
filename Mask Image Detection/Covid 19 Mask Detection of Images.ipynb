{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "\n",
    "import random\n",
    "\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "from os import getcwd\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import imutils\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.image  as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(main_path):\n",
    "\n",
    "    withmask_path = main_path+'withmaskreal'\n",
    "\n",
    "    withoutmask_path = main_path+'withoutmaskreal'\n",
    "\n",
    "    # number of (images) that are in the the folder named 'with_mask' \n",
    "\n",
    "    m_pos = len(listdir('C:/experiment/data/with_mask'))\n",
    "\n",
    "    # number of (images) that are in the the folder named 'without_mask' \n",
    "\n",
    "    m_neg = len(listdir('C:/experiment/data/without_mask'))\n",
    "\n",
    "    # number of all examples\n",
    "\n",
    "    m = (m_pos+m_neg)\n",
    "\n",
    "    pos_prec = (m_pos* 100.0)/ m\n",
    "\n",
    "    neg_prec = (m_neg* 100.0)/ m\n",
    "\n",
    "    print(f\"Number of examples: {m}\")\n",
    "\n",
    "    print(f\"Percentage of positive examples: {pos_prec}%, number of pos examples: {m_pos}\") \n",
    "\n",
    "    print(f\"Percentage of negative examples: {neg_prec}%, number of neg examples: {m_neg}\")    \n",
    "    augmented_data_path = 'C:/experiment/dest_folder/val'    \n",
    "\n",
    "data_summary(augmented_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "\n",
    "    dataset = []  \n",
    "\n",
    "    for unitData in os.listdir(SOURCE):\n",
    "\n",
    "        data = SOURCE + unitData\n",
    "\n",
    "        if(os.path.getsize(data) > 0):\n",
    "\n",
    "            dataset.append(unitData)\n",
    "\n",
    "        else:\n",
    "\n",
    "            print('Skipped ' + unitData)\n",
    "\n",
    "            print('Invalid file i.e zero size')  \n",
    "\n",
    "    train_set_length = int(len(dataset) * SPLIT_SIZE)\n",
    "\n",
    "    test_set_length = int(len(dataset) - train_set_length)\n",
    "\n",
    "    shuffled_set = random.sample(dataset, len(dataset))\n",
    "\n",
    "    train_set = dataset[0:train_set_length]\n",
    "\n",
    "    test_set = dataset[-test_set_length:]     \n",
    "\n",
    "    for unitData in train_set:\n",
    "\n",
    "        temp_train_set = SOURCE + unitData\n",
    "\n",
    "        final_train_set = TRAINING + unitData\n",
    "\n",
    "        copyfile(temp_train_set, final_train_set)  \n",
    "\n",
    "    for unitData in test_set:\n",
    "\n",
    "        temp_test_set = SOURCE + unitData\n",
    "\n",
    "        final_test_set = TESTING + unitData\n",
    "\n",
    "        copyfile(temp_test_set, final_test_set)      \n",
    "\n",
    "WITHMASK_SOURCE_DIR = \"C:/experiment/dest_folder/val/with_mask/\"\n",
    "\n",
    "TRAINING_WITHMASK_DIR = \"C:/experiment/dest_folder/train/with_mask/\"\n",
    "\n",
    "TESTING_WITHMASK_DIR = \"C:/experiment/dest_folder/test/without_mask/\"\n",
    "\n",
    "WITHOUTMASK_SOURCE_DIR = \"C:/experiment/dest_folder/val/without_mask/\"\n",
    "\n",
    "TRAINING_WITHOUTMASK_DIR = \"C:/experiment/dest_folder/train/without_mask/\"\n",
    "\n",
    "TESTING_WITHOUTMASK_DIR = \"C:/experiment/dest_folder/test/without_mask/\"\n",
    "\n",
    "split_size = .8\n",
    "\n",
    "split_data(WITHMASK_SOURCE_DIR, TRAINING_WITHMASK_DIR, \n",
    "\n",
    "TESTING_WITHMASK_DIR, split_size)\n",
    "\n",
    "split_data(WITHOUTMASK_SOURCE_DIR, TRAINING_WITHOUTMASK_DIR, \n",
    "\n",
    "TESTING_WITHOUTMASK_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of images with facemask in the training set'with_mask':\", len(os.listdir('C:/experiment/dest_folder/train/with_mask')))\n",
    "\n",
    "print(\"number of images with facemask in the test set'with_mask':\", len(os.listdir('C:/experiment/dest_folder/test/with_mask')))\n",
    "\n",
    "print(\"number of images without facemask in the training set'without_mask':\", len(os.listdir('experiment/dest_folder/train/without_mask')))\n",
    "\n",
    "print(\"number of images without facemask in the test set'without_mask':\",\n",
    "\n",
    "len(os.listdir('experiment/dest_folder/test/without_mask')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', \n",
    "\n",
    "    input_shape=(150, 150, 3)),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = \"C:/experiment/dest_folder/train\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "\n",
    "                                   rotation_range=40,\n",
    "\n",
    "                                   width_shift_range=0.2,\n",
    "\n",
    "                                   height_shift_range=0.2,\n",
    "\n",
    "                                   shear_range=0.2,\n",
    "\n",
    "                                   zoom_range=0.2,\n",
    "\n",
    "                                   horizontal_flip=True,\n",
    "\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "\n",
    "                                                    batch_size=10, \n",
    "\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "VALIDATION_DIR = \"C:/experiment/dest_folder/test\"\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    " \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    "\n",
    "                                                         batch_size=10, \n",
    "\n",
    "                                                         target_size=(150, 150))\n",
    "\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istory = model.fit_generator(train_generator,\n",
    "\n",
    "                              epochs=30,\n",
    "\n",
    "                              validation_data=validation_generator,\n",
    "\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "model.save('my_model_facemask.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import argparse\n",
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "from natsort import natsorted, ns\n",
    " \n",
    "\n",
    "input_file_path = \"C:/experiment/data/with_mask/0-with-mask.jpg\"\n",
    " \n",
    "\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "\n",
    "prototxtPath = \"C:/experiment/deploy.prototxt\"\n",
    "\n",
    "weightsPath = \"C:/experiment/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "# load the face mask detector\n",
    "\n",
    "print(\"[INFO] loading face mask detector model...\")\n",
    "\n",
    "model = load_model(\"C:/experiment/mymodel.h5\")\n",
    "\n",
    "def process_images(input_file_path):\n",
    "\n",
    "  # load the input imag\n",
    "\n",
    "  # dimensions\n",
    "\n",
    "  image = cv2.imread(input_file_path)\n",
    "\n",
    "  (h, w) = image.shape[:2]\n",
    " \n",
    "\n",
    "  # construct a blob from the image\n",
    "\n",
    "  blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
    "\n",
    "    (104.0, 177.0, 123.0))\n",
    "\n",
    " # pass the blob through the network and obtain the face detections\n",
    "\n",
    "  print(\"[INFO] computing face detections...\")\n",
    "\n",
    "  net.setInput(blob)\n",
    "\n",
    "  detections = net.forward()\n",
    "\n",
    "  # loop over the detections\n",
    "\n",
    "  for i in range(0, detections.shape[2]):\n",
    "\n",
    "    # extract the confidence associated with\n",
    "\n",
    "    # the detection\n",
    "\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    # filter out weak detections by ensuring the confidence is\n",
    "\n",
    "    # greater than the minimum confidence\n",
    "\n",
    "    if confidence > 0.5:\n",
    "\n",
    "      # compute the (x, y)-coordinates of the bounding box for\n",
    "\n",
    "      # the object\n",
    "\n",
    "      box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\n",
    "      (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "      # ensure the bounding boxes fall within the dimensions of\n",
    "\n",
    "      # the frame\n",
    "\n",
    "      (startX, startY) = (max(0, startX), max(0, startY))\n",
    "\n",
    "      (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "      # extract the face ROI, convert it from BGR to RGB channel\n",
    "\n",
    "      # ordering, resize it to 150x150, and preprocess it\n",
    "\n",
    "      face = image[startY:endY, startX:endX]\n",
    "\n",
    "      face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "      face = cv2.resize(face, (150, 150))\n",
    "\n",
    "      face = img_to_array(face)\n",
    "\n",
    "      face = preprocess_input(face)\n",
    "\n",
    "      face = np.expand_dims(face, axis=0)\n",
    "\n",
    "      # pass the face through the model to determine if the face\n",
    "\n",
    "      # has a mask or not\n",
    "\n",
    "      (mask, withoutMask) = model.predict(face)[0]\n",
    "\n",
    "      # determine the class label and color we'll use to draw\n",
    "\n",
    "      # the bounding box and text\n",
    "\n",
    "      label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "\n",
    "      color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "   # include the probability in the label\n",
    "\n",
    "      label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "      # display the label and bounding box rectangle on the output\n",
    "\n",
    "      # frame\n",
    "\n",
    "      cv2.putText(image, label, (startX, startY - 10),\n",
    "\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "\n",
    "      cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "  # show the output image\n",
    "\n",
    "  save_path = input_file_path.split(\".\",1)\n",
    "\n",
    "  cv2_imshow(image)\n",
    "\n",
    "#start the process\n",
    "\n",
    "process_images(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
